{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "Feature Selection \n",
    "================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "theme_set(theme_bw())\n",
    "source(\"load_hess.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "It is often assumed that in any one particular problem the expression\n",
    "patterns of most genes---or, more generally, the values of most\n",
    "features in a high-dimensional data set---are either:\n",
    "-   uninformative or\n",
    "-   redundant with a few maximally useful markers.\n",
    "\n",
    "*Feature selection* attempts to identify a restricted set of such\n",
    "useful features for inclusion in a classification model while\n",
    "discarding the rest.\n",
    "\n",
    "While feature selection may or may not improve the performance of a\n",
    "particular classifier applied to a particular problem, it can\n",
    "1.  reduce computational workload,\n",
    "2.  help to avoid overfitting\n",
    "    -   (though feature selection can itself be susceptible to\n",
    "        overfitting!), and\n",
    "    \n",
    "3.  facilitate assessment of model using less high-throughput\n",
    "    platforms.\n",
    "\n",
    "A good, if somewhat dated, reference on the use of feature selection\n",
    "methods in bioinformatics is [@saeys2007review], which breaks down\n",
    "feature selection methods into the following three categories:\n",
    "\n",
    "**Filter**\n",
    ":   Selection done before and independently of\n",
    "    classifier construction. Can be univariate or multivariate.\n",
    "\n",
    "**Wrapper**\n",
    ":   Embed classifier construction within feature\n",
    "    selection process. Heuristic search methods compare models, favor\n",
    "    adding or removing features based on optimization of some\n",
    "    specified metric on resulting classifiers.\n",
    "\n",
    "**Embedded**\n",
    ":   Feature selection is inherently built into\n",
    "    some classifier construction methods.\n",
    "\n",
    "For a nice figure providing more detail on the advantages and\n",
    "disadvantages associated with each of these categories, along with\n",
    "some standard examples, you can follow the link to\n",
    "<https://academic.oup.com/view-large/1739292>.\n",
    "\n",
    "I can't do justice to the wide range of feature selection techniques\n",
    "in the limited time available in this course, so we're going to focus\n",
    "on one particularly simple method: a plain old $t$-test. Here's an R\n",
    "function to select a fixed number of features according to $t$-test\n",
    "$p$-values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "## install.packages(\"BiocManager\")     ## uncomment and run if necessary\n",
    "## BiocManager::install(\"genefilter\")  ## uncomment and run if necessary\n",
    "selectByTTest = function(x, y, m) {\n",
    "     ## use genefilter package for efficient repeated t-test functions\n",
    "     ## (here will use genefilter::colttests)\n",
    "    require(genefilter)\n",
    "     ## assume x is samples-in-rows, genes-in-columns format!\n",
    "    p = colttests(x, y)$p.value\n",
    "     ## sort genes by order of p, return names of first m\n",
    "    return(colnames(x)[order(p)[1:m]])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "In order to use this feature selection method as part of a\n",
    "classification \"pipeline\", we need to connect it (\"upstream\") to a\n",
    "(\"downstream\") classification algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    " ## arguments to featSelFit:\n",
    " ## - x is matrix or data.frame of feature values\n",
    " ## - y is factor of classification labels\n",
    " ## - selector is function taking x and y as arguments\n",
    " ##                        and returning selected feature names\n",
    " ## - fitter is a function taking x and y as arguments\n",
    " ##                        and returning fit model object\n",
    "featSelFit = function(x, y, selector, fitter) {\n",
    "    require(caret)\n",
    "      ## extract features using selector function:\n",
    "    features = selector(x, y)\n",
    "     ## retain only selected features in x for fitting knn model:\n",
    "    x = x[ , features, drop=FALSE]\n",
    "     ## fit the desired model using the selected feature set:\n",
    "    fit = fitter(x, y)\n",
    "     ## package results in list; need to remember features and fit:\n",
    "    out = list(features=features, fit=fit)\n",
    "     ## declare this list to be a FeatureSelectedFitModel object\n",
    "     ## (this will be important for implementing predict method below):\n",
    "    class(out) = \"FeatureSelectedFitModel\"\n",
    "    return(out)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "Given that we want to make predictions using the\n",
    "`FeatureSelectedFitModel` object output by `featSelFit`, we'll\n",
    "need to implement a `predict` method for this new (S3) class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    " ## arguments for predict method telling R how to make predictions from a\n",
    " ## FeatureSelectedFitModel object:\n",
    " ## - object is a list with class attribute \"FeatureSelectedFitModel\"\n",
    " ##   (so it should have named elements object$fit, object$features)\n",
    " ## - x is matrix or data.frame of feature values to make predictions for\n",
    " ## - ... any other arguments are passed along to predict.knn3\n",
    "predict.FeatureSelectedFitModel = function(object, x, ...) {\n",
    "     ## first keep only the features in object$features:\n",
    "    x = x[ , object$features, drop=FALSE]\n",
    "     ## now predict using object$fit on the selected features:\n",
    "    return(predict(object$fit, x, ...))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "OK, now we're ready to try our $t$-test feature selection-then-knn\n",
    "classify modeling strategy out on the Hess data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    " ## define bindArgs function to allow fixing (i.e. binding)\n",
    " ## the argument for\n",
    " ## - parameter m in selectByTTest and\n",
    " ## - parameter k in knn3\n",
    " ## to extract a function of only the feature data x and\n",
    " ## output class vector y for use in featSelFit:\n",
    "bindArgs = function(f, ...) {\n",
    "    args = list(...)\n",
    "    return(function(...) {do.call(f, args=c(list(...), args))})\n",
    "}\n",
    " ## now let's fit the model:\n",
    "fsKnnFit = featSelFit(x = t(hessTrain),\n",
    "                      y = hessTrainY,\n",
    "                      selector = bindArgs(selectByTTest, m=25),\n",
    "                      fitter = bindArgs(knn3, k=9))\n",
    " ## ...and make predictions using with with fit model:\n",
    "fsKnnTestPredictionProbs = predict(fsKnnFit, t(hessTest))\n",
    "head(fsKnnTestPredictionProbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "fsKnnTestPredictionClass = predict(fsKnnFit, t(hessTest), type=\"class\")\n",
    "head(fsKnnTestPredictionClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "table(fsKnnTestPredictionClass, hessTestY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "fsKnnCaretized = list(\n",
    "    library = \"genefilter\",\n",
    "    type = \"Classification\",\n",
    "    parameters = data.frame(\n",
    "        parameter = c(\"m\", \"k\"),\n",
    "        class = c(\"integer\", \"integer\"),\n",
    "        label = c(\"number features\", \"number neighbors\")\n",
    "    ),\n",
    "     ## try all combinations of m in 10, 100, 1000, 10000\n",
    "     ##                      and k in 5, 9, 19\n",
    "    grid = function(x, y, len=NULL, ...) {\n",
    "        expand.grid(m=c(10, 100, 1000, 10000), k=c(5, 9, 19))\n",
    "    },\n",
    "     ## fit should be function of x, y and then any parameters\n",
    "     ## (here these are m and k) which must be in list named params:\n",
    "    fit = function(x, y, param, ...) {\n",
    "        featSelFit(x,\n",
    "                   y,\n",
    "                   selector = bindArgs(selectByTTest, m=param$m),\n",
    "                   fitter = bindArgs(knn3, k=param$k))\n",
    "    },\n",
    "     ## caret::train wants predict to make class predictions:\n",
    "     ## - first argument must be named modelFit\n",
    "     ## - second should be named newdata\n",
    "    predict = function(modelFit, newdata, ...) {\n",
    "        predict(modelFit, newdata, type=\"class\")\n",
    "    },\n",
    "     ## let caret::train use plain-old predict\n",
    "     ## (will really be predict.FeatureSelectedFitModel)\n",
    "     ## to make probabilistic predictions from fit model object\n",
    "    prob = predict\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "We can now supply `fsKnnCaretized` as the `method` argument for `train`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "caretOut = train(x = t(hessTrain),\n",
    "                 y = hessTrainY,\n",
    "                 method = fsKnnCaretized,\n",
    "                 trControl = trainControl(method=\"cv\", number=5))\n",
    "caretOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "The objects returned by `caret::train` (of class `train`,\n",
    "naturally) can be `ggplot`ed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "ggplot(caretOut) + scale_x_log10()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "It is interesting to note that for this data set the size of the\n",
    "selected feature set will vary considerably upon re-running the\n",
    "cross-validation.\n",
    "Feature Extraction \n",
    "==================\n",
    "\n",
    "An alternative approach to feature selection to mitigating the\n",
    "problems of overfitting and high computational workload associated\n",
    "with machine learning with high-dimensional data is *feature extraction*.\n",
    "\n",
    "While\n",
    "\n",
    "**feature selection**\n",
    ":   reduces the size of the feature set\n",
    "    presented to a classification or regression algorithm by retaining\n",
    "    only a small subset of the feature set,\n",
    "\n",
    "**feature extraction**\n",
    ":   applies a mathematical\n",
    "    transformation to the high-dimensional input data to derive a\n",
    "    low-dimensional feature set.\n",
    "\n",
    "For example, if you were trying to classify day vs. night situations\n",
    "with digital image data, you could simply average the intensities of\n",
    "all pixels together to extract a \"light level\" feature. Note that\n",
    "this single extracted feature still depends on the value of *all*\n",
    "of the input features, so it doesn't reduce the amount of data you\n",
    "need to collect to evaluate the model, but it does massively diminish\n",
    "the complexity of the task confronting whatever downstream\n",
    "classification algorithm you apply!\n",
    "\n",
    "With gene expression data, the most obvious and widely used method of\n",
    "feature extraction is PCA, so we will use this for our example. Recall\n",
    "that the PC1 scores of a sample are defined as a weighted sum (or\n",
    "linear combination) of feature values with the feature weights learned\n",
    "so as to optimally model feature values based on (feature mean +\n",
    "feature weight * sample score). Higher PCs can then be defined so as\n",
    "to in a similar way so as to successively improve the model.\n",
    "\n",
    "When building a classification or regression model using PCA for\n",
    "feature extraction, we learn the feature weights for the various\n",
    "principal components (which make up the elements of the \"rotation\n",
    "matrix\"), as well as the feature mean values, using the training set\n",
    "(only). These weights and means are then fixed parameters of the fit\n",
    "model and should not be updated when presented with test data!\n",
    "\n",
    "Here is a function for learning the PCs from a training set (provided\n",
    "to the function as a matrix of feature values `x`) which returns a\n",
    "function `extractor` for assessing the sample scores for a test set\n",
    "`newdata`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    " ## arguments to extractPCs\n",
    " ## - x is matrix or data.frame of feature values\n",
    " ## - m is number of principal component features to extract\n",
    "extractPCs = function(x, m, ...) {\n",
    "     ## assume x is samples-in-rows, genes-in-columns format!\n",
    "     ## training-set-estimated mean expression of each gene:\n",
    "    mu = colMeans(x)\n",
    "    pca = prcomp(x, center=TRUE, scale.=FALSE)\n",
    "     ## extract matrix needed to project new data onto first m extracted PCs:\n",
    "    projection = pca$rotation[ , 1:m, drop=FALSE]\n",
    "     ## define extraction function to extract features from new data:\n",
    "    extractor = function(newdata) {\n",
    "         ## sweep out training-set-estimated gene means:\n",
    "        newdata = sweep(newdata, 2, mu, '-')\n",
    "        return(newdata %*% projection)\n",
    "    }\n",
    "     ## return the function \"extractor\" which can be applied to newdata;\n",
    "     ## this function yields coordinates of samples in newdata in PC-space\n",
    "     ## learned from the training data passed in as x argument.\n",
    "    return(extractor)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "We can hook this function for learning the PC features to extract from\n",
    "data up to our knn classification algorithm in a manner similar to\n",
    "what we did for feature selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    " ## arguments to pcaKnn:\n",
    " ## - x is matrix or data.frame of feature values\n",
    " ## - y is factor of classification labels\n",
    " ## - extractionLearner is function taking x and y as arguments and\n",
    " ##                                 returning extractor function\n",
    " ## - fitter is a function taking x and y as arguments and\n",
    " ##                        returning fit model object\n",
    "featExtFit = function(x, y, extractionLearner, fitter) {\n",
    "     ## use extractionLearner function to learn extractor using data x, y:\n",
    "    extractor = extractionLearner(x, y)\n",
    "     ## extract features from x for fitting knn model:\n",
    "    x = extractor(x)\n",
    "     ## fit the desired model using the selected feature set:\n",
    "    fit = fitter(x, y)\n",
    "     ## package results in list; need to remember extractor and fit:\n",
    "    out = list(extractor=extractor, fit=fit)\n",
    "     ## declare this list to be a FeatureExtractedFitModel object:\n",
    "    class(out) = \"FeatureExtractedFitModel\"\n",
    "    return(out)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "Once again we need to implement a `predict` method for our newly\n",
    "defined `FeatureExtractedFitModel` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    " ## arguments for predict method telling R how to make predictions from a\n",
    " ## FeatureExtractedFitModel object:\n",
    " ## - object is a list with class attribute \"FeatureExtractedFitModel\"\n",
    " ##   (so it should have named elements object$fit, object$extractor)\n",
    " ## - x is matrix or data.frame of feature values to make predictions for\n",
    " ## - ... any other arguments are passed along to predict.knn3\n",
    "predict.FeatureExtractedFitModel = function(object, x, ...) {\n",
    "     ## first extract the features using object$extractor:\n",
    "    x = object$extractor(x)\n",
    "     ## now predict using object$fit on the extracted features:\n",
    "    return(predict(object$fit, x, ...))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "And now we can go ahead and try modeling the Hess data using an ML\n",
    "pipeline with PCA feature extraction feeding into knn classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "pcaKnnFit = featExtFit(x = t(hessTrain),\n",
    "                       y = hessTrainY,\n",
    "                       extractionLearner = bindArgs(extractPCs, m=5),\n",
    "                       fitter = bindArgs(knn3, k=9))\n",
    "pcaKnnTestPredictionClass = predict(pcaKnnFit, t(hessTest), type=\"class\")\n",
    "table(pcaKnnTestPredictionClass, hessTestY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "In order to do cross-validation with `caret::train`, we'll need to\n",
    "package everything up in a list with all of the named components\n",
    "`train` will want to see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "pcaKnnCaretized = list(\n",
    "    library = NULL,\n",
    "    type = \"Classification\",\n",
    "    parameters = data.frame(\n",
    "        parameter = c(\"m\", \"k\"),\n",
    "        class = c(\"integer\", \"integer\"),\n",
    "        label = c(\"number features\", \"number neighbors\")\n",
    "    ),\n",
    "     ## try all combinations of m in 3, 4, 5 and k in 5, 9, 19\n",
    "    grid = function(x, y, len=NULL, ...) {\n",
    "        expand.grid(m=3:5, k=c(5, 9, 19))\n",
    "    },\n",
    "     ## fit should be function of x, y and named list params:\n",
    "    fit = function(x, y, param, ...) {\n",
    "        featExtFit(x,\n",
    "                   y,\n",
    "                   extractionLearner = bindArgs(extractPCs, m=param$m),\n",
    "                   fitter = bindArgs(knn3, k=param$k))\n",
    "    },\n",
    "     ## caret::train wants predict to make class predictions:\n",
    "     ## arguments must be named modelFit and newdata\n",
    "    predict = function(modelFit, newdata, ...) {\n",
    "        predict(modelFit, newdata, type=\"class\")\n",
    "    },\n",
    "    prob = predict\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "Let's give this `train` and let it do its thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "caretOut = train(x = t(hessTrain),\n",
    "                 y = hessTrainY,\n",
    "                 method = pcaKnnCaretized,\n",
    "                 trControl = trainControl(method=\"cv\", number=5))\n",
    "caretOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "ggplot(caretOut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "Going deeper \n",
    "============\n",
    "\n",
    "It may have occurred to you that feature selection can be seen as a\n",
    "particularly simple type of feature extraction which \"transforms\"\n",
    "the input feature matrix by simply projecting it onto a few select\n",
    "dimensions.\n",
    "\n",
    "Similarly, just as we previously described the transformation of a\n",
    "data set by PCA feature extraction as a type of prediction, we could\n",
    "reverse viewpoints and frame the action of `predict` methods as\n",
    "really just another type of data transformation---albeit with some\n",
    "peculiar restrictions on the transformed output values (e.g., must be\n",
    "probability scores, must be class labels from particular set of\n",
    "possibilities, etc.).\n",
    "\n",
    "From this point of view, an ML pipeline is an ordered sequence of ML\n",
    "algorithm steps. To train such a pipeline, we go through the sequence:\n",
    "-   training the $i^{\\text{th}}$ ML algorithm step using the\n",
    "    transformed output from step $i-1$ as our input feature matrix for\n",
    "    the current step,\n",
    "-   thus learning fit submodel $i$.\n",
    "-   We then transform the output again using our newly trained fit\n",
    "    submodel $i$ and pass it along as input feature matrix to ML\n",
    "    algorithm $i+1$.\n",
    "\n",
    "To make predictions using the fit pipeline model resulting from this\n",
    "training procedure, we iterate through the the ordered sequence of\n",
    "trained submodels, taking the transformed output from step $i-1$ as\n",
    "input feature matrix to be transformed by fit submodel $i$ and then\n",
    "passed along to step $i+1$. The predicted values are then whatever is\n",
    "output from the final step of the fit pipeline.\n",
    "\n",
    "The field of *deep learning*\n",
    "([@goodfellow2016deep]) builds such pipelines out of individual\n",
    "steps (\"layers\") for which the argument feature matrix and output\n",
    "transformed feature matrix are similar enough in nature that the same\n",
    "type of submodel can be linked together repeatedly to generate very\n",
    "long pipelines. Because each individual layer in a deep learning model\n",
    "is itself generally composed of many similar subunits (artificial\n",
    "\"neurons\"), the structure of a deep learning model is typically\n",
    "referred to as a *network* instead of a pipeline, and we speak of\n",
    "a many-layer network as being *deep* instead of long.\n",
    "\n",
    "Deep learning is beyond the scope of this course, but if you work on\n",
    "any projects involving machine learning long enough it's bound to come\n",
    "up at some point. Especially in problems with very large numbers of\n",
    "$n$ sampling units, deep learning models can often outperform other\n",
    "methods, though they are prone to overfitting and tend to require a\n",
    "great deal of time and effort to get working correctly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
