{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "Support Vector Machines \n",
    "======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "library(caret)\n",
    "library(ggplot2)\n",
    "theme_set(theme_bw())\n",
    "source(\"ggfuntile.R\")\n",
    "source(\"maclearn_utils_2020.R\")\n",
    "source(\"load_hess.R\")\n",
    "twoProbeData = t(hessTrain)[ , c(\"205548_s_at\", \"201976_s_at\")]\n",
    "colnames(twoProbeData) =\n",
    "        probeAnnot[colnames(twoProbeData), \"Gene.Symbol\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "Linear models, including logistic regression and DLDA, are very useful\n",
    "in many contexts but do have some characteristics which can be\n",
    "limiting. *Support vector machines*, or SVMs\n",
    "([@cortes1995support; @hastie2009elements]), are a type of\n",
    "supervised classifcation algorithm which address two particular\n",
    "limitations:\n",
    "1.  The parameters fit by classical linear classification algorithms\n",
    "    are generally sensitive to extremely easy-to-call sampling units\n",
    "    -   (correctly called sampling units whose feature vectors are\n",
    "        very far from the decision boundary)\n",
    "    -   even when a more accurate classifier might result from\n",
    "        parameters which move these outlier probabilities \"in the wrong\n",
    "        direction\"\n",
    "    -   but not far enough to change the final classification made.\n",
    "    \n",
    "2.  Linearity of response is a very strong and often unrealistic\n",
    "    assumption; many real-world response patterns are highly nonlinear.\n",
    "\n",
    "The term \"support vectors\" in the name SVMs refers to the feature\n",
    "vectors corresponding to samples which are close to being on the wrong\n",
    "side of the decision boundary; for a nice illustration check out\n",
    "<https://en.wikipedia.org/wiki/Support_vector_machine#/media/File:SVM_margin.png>.\n",
    "\n",
    "SVM models are fit by positioning the decision boundary so as to keep\n",
    "the support vectors as far on the right sides as possible; the\n",
    "parameters defining the decision boundary thus ultimately depend only\n",
    "on the sampling units corresponding to the support vectors, thus\n",
    "mitigating point 1 above.\n",
    "\n",
    "Point 2 can also be addressed in the SVM framework using a\n",
    "mathematical technique known as the \"kernel trick.\" The math here is\n",
    "beyond the scope of these notes, but the core idea is that you first\n",
    "apply a nonlinear transformation to the data matrix and then apply SVM\n",
    "in the transformed coordinates, kind of like when we did feature\n",
    "extraction prior to fitting a knn model. The trick is that certain\n",
    "special transformations lead to model fitting problems which may be\n",
    "described in terms of the *un*transformed coordinates in\n",
    "intuitively interesting and useful ways.\n",
    "\n",
    "(What makes this so tricky is that while it has been proven that there\n",
    "do indeed exist particular transformations that lead to the problems\n",
    "nicely describable as modified versions of the original SVM problem in\n",
    "untransformed coordinates, the actual transformations\n",
    "themselves---which are very complicated---aren't actually needed in\n",
    "doing the computations, just the modified problem description in the\n",
    "original feature space!)\n",
    "\n",
    "We'll focus on a specific class of transformations: those which\n",
    "replace the standard dot products appearing in the mathematical\n",
    "expressions composing the original SVM problem with so-called \"radial\n",
    "basis function\" (RBF) kernels.\n",
	"\n",
    "We'll do this in R using the `kernlab` library; just as we did with\n",
    "`lm` and `glm`, we'll define a convenience function for using the\n",
    "`ksvm` function from this library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "## install.packages(\"kernlab\")  ## uncomment and run if necessary\n",
    " ## arguments to svmFitter:\n",
    " ## - x is matrix or data.frame of feature values\n",
    " ## - y is factor of classification labels\n",
    " ## - C is cost-of-constraints violation parameter associated with\n",
    " ##   feature vectors getting too close to wrong side of decision\n",
    " ##   boundary\n",
    " ## - sigma is inverse width parameter for radial basis function;\n",
    " ##   higher values of sigma imply more local/less global fits\n",
    "svmFitter = function(x, y, C=1, sigma=0.05, ...) {\n",
    "    require(kernlab)\n",
    "    ksvm(y ~ .,\n",
    "         data = data.frame(x, y=y, check.names=FALSE),\n",
    "         C = C,\n",
    "         kpar = list(sigma=sigma),\n",
    "         prob.model = TRUE,\n",
    "         ...)\n",
    " ## prob.model=TRUE argument above supplements traditional SVM algorithm\n",
    " ## to allow probabilistic predictions as well as discrete classifications\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "While SVM models are somewhat more complex than the simplicity that is\n",
    "knn, revisiting our two probe set contour plotting strategy using a\n",
    "range of `sigma` parameter values reveals a striking similarity in\n",
    "the types of decision boundaries learned by the methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "twoProbeSvmFitSig0p25 = svmFitter(twoProbeData, hessTrainY, sigma=0.25)\n",
    "predictionContour(twoProbeSvmFitSig0p25,\n",
    "                  twoProbeData, hessTrainY, \"sigma = 0.25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "Increasing the `sigma` parameter creates a more local---and in this\n",
    "case, likely more overfit---SVM model (similar to *decreasing*\n",
    "the number $k$ of nearest neighbors in a knn model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "twoProbeSvmFitSig1p25 = svmFitter(twoProbeData, hessTrainY, sigma=1.25)\n",
    "predictionContour(twoProbeSvmFitSig1p25,\n",
    "                  twoProbeData, hessTrainY, \"sigma = 1.25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "And increasing `sigma` still further\\..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "twoProbeSvmFitSig6p25 = svmFitter(twoProbeData, hessTrainY, sigma=6.25)\n",
    "predictionContour(twoProbeSvmFitSig6p25,\n",
    "                  twoProbeData, hessTrainY, \"sigma = 6.25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "While SVM models using RBF kernels produce classifiers with somewhat\n",
    "similar properties to knn, you can see that the decision boundaries\n",
    "tend to be smoother. Why might this be?\n",
    "\n",
    "The knn approach doesn't care whether the $(k+1)^{\\text{th}}$ nearest\n",
    "neighbor is just ever so slightly farther away than the\n",
    "$k^{\\text{th}}$, or whether the $k^{\\text{th}}$ nearest neighbor is 10\n",
    "times farther away than the the $(k-1)^{\\text{th}}$, but just gives\n",
    "equal weight to the closest $k$ and zero weight to everything else.\n",
    "\n",
    "In contrast, the SVM-with-RBF-kernel approach can be seen as making\n",
    "predictions using on a *weighted* sum of the known\n",
    "classifications for nearby training data, with the weightings based on\n",
    "a smooth function of the distance from training feature vector to the\n",
    "feature vector to be classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "set.seed(123)            ## for replicability\n",
    "pcaSvmFit = featExtFit(\n",
    "    x = t(hessTrain),\n",
    "    y = hessTrainY,\n",
    "    extractionLearner = bindArgs(extractPCs, m=5),\n",
    "    fitter = bindArgs(svmFitter, sigma=0.25)\n",
    ")\n",
    " ## b/c SVM is not primarily a probabilistic classifier\n",
    " ## predict method for kvsm objects returns class labels by default\n",
    "pcaSvmTestPredictionClass = predict(\n",
    "    pcaSvmFit,\n",
    "    data.frame(t(hessTest), check.names=FALSE)\n",
    ")\n",
    "table(pcaSvmTestPredictionClass, hessTestY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "We'll assess the performance of this classifier in the training set\n",
    "using `caret::train` as well, but instead of avoiding resubstitution\n",
    "bias using cross-validation we'll try an alternative resampling\n",
    "technique known as *bootstrapping*.\n",
    "Bootstrapping \n",
    "=============\n",
    "\n",
    "Machine learning is generally less concerned with questions about\n",
    "whether the internal structure of a model is correct, necessary or\n",
    "interpretable than is classical statistics, but there are still times\n",
    "when we'd like to be able to characterize the uncertainty or\n",
    "repeatability associated with an estimated parameter value.\n",
    "\n",
    "Put another way: if we had another data set generated in the same way\n",
    "as the one we do have, how similar would the value we estimated for\n",
    "this or that parameter be to what we get using the actually realized\n",
    "training data? Do we expect to get basically the same value or\n",
    "something wildly different?\n",
    "\n",
    "For linear models, the literature abounds with useful analytical\n",
    "results on confidence intervals, credible intervals, and the like. But\n",
    "for other types of modeling strategies, this is rarely the case!\n",
    "\n",
    "If gathering data were cheap and easy, we could just go ahead and\n",
    "replicate\n",
    "-   the experiment which generated the data and then\n",
    "-   re-fit the model to the newest round of data\n",
    "\n",
    "many times to empirically estimate the distribution of fit model\n",
    "parameters.\n",
    "\n",
    "*Bootstrapping* is a clever approach to *simulate* such\n",
    "replication using just the one data set we actually have\n",
    "([@tibshirani1993introduction]). The bootstrapping process\n",
    "consists of:\n",
    "1.  Generate a case-resampled data set with feature matrix\n",
    "    $\\mathbf{\\underline{X}}^{\\text{boot}}$ and outcome vector\n",
    "    $\\mathbf{y}^{\\text{boot}}$ by drawing $n$ random integers\n",
    "    $1 \\leq r_i \\leq n$ *with replacement* and setting\n",
    "    $$\\begin{aligned}\n",
    "       x_{ig}^{\\text{boot}} &= x_{r_i g} \\\\\n",
    "       y_i^{\\text{boot}} &= y_{r_i}\n",
    "      \\end{aligned}$$\n",
    "    Note that the $r_i$ will generally not be unique: $r_i$ and $r_j$\n",
    "    may be the same sampling unit even when $i \\neq j$, so that the same\n",
    "    sampling unit may be included multiple times in the resampled data\n",
    "    set!\n",
    "2.  Fit desired model to resampled feature matrix\n",
    "    $\\mathbf{\\underline{X}}^{\\text{boot}}$ and outcome vector\n",
    "    $\\mathbf{y}^{\\text{boot}}$ to learn parameters\n",
    "    $\\mathbf{y}^{\\text{boot}}$\n",
    "    -   $\\boldsymbol{\\theta}$ is just way of writing set of all\n",
    "        parameters needed by model pulled together into one big vector,\n",
    "        while\n",
    "    -   the \"hat\" on top of $\\hat{\\boldsymbol{\\theta}}$ indicates\n",
    "        that we are talking about a specific data-derived estimate of the\n",
    "        parameter values $\\boldsymbol{\\theta}$, and\n",
    "    -   superscript \"boot\" on $\\hat{\\boldsymbol{\\theta}}^{\\text{boot}}$\n",
    "        just says the parameters were learned from the bootstrap-resampled\n",
    "        data as opposed to the original trainind data set.\n",
    "    \n",
    "3.  Use fit model with parameters\n",
    "    $\\hat{\\boldsymbol{\\theta}}^{\\text{boot}}$ to estimate parameter or\n",
    "    statistic $\\hat{\\Omega}^{\\text{boot}}$ of interest.\n",
    "4.  Repeat steps 1-3 $B$ times, obtaining values\n",
    "    $\\hat{\\Omega}_b^{\\text{boot}}$ for $b \\in \\{1,\\ldots,B\\}$ using fit models\n",
    "    with parameters $\\hat{\\boldsymbol{\\theta}}_b^\\text{boot}$.\n",
    "\n",
    "Note that because bootstrap resampling generates new simulated data\n",
    "sets of the same size $n$ as the original data set but in which some\n",
    "sampling units are repeated, there will necessarily be some sampling\n",
    "units that get left out in any particular resampled data set: on\n",
    "average, a fraction $\\frac{1}{e} \\approx 0.368$ of all sampling units\n",
    "will be omitted in each bootstrap sample.\n",
    "Bootstrapping for Performance Estimation \n",
    "----------------------------------------\n",
    "\n",
    "Bootstrapping can also be used as an alternative to cross-validation\n",
    "for estimation of prediction error $\\Omega$.\n",
    "\n",
    "How should we go about this?\n",
    "-   We might try to estimate distribution of prediction error\n",
    "    $\\{\\hat{\\Omega}_b^{\\text{full}}\\}$\n",
    "-   making predictions with each bootstrap model $b$ with parameters\n",
    "    $\\hat{\\boldsymbol{\\theta}}_b^\\text{boot}$ applied to full (original)\n",
    "    training set $\\mathbf{\\underline{X}}$.\n",
    "\n",
    "However, since bootstrap training sets were drawn from the same\n",
    "original feature matrix $\\mathbf{\\underline{X}}$,\n",
    "$\\{\\hat{\\Omega}_b^{\\text{full}}\\}$ will suffer from resubstitution\n",
    "bias.\n",
    "\n",
    "Instead we could follow cross-validation methodology:\n",
    "-   use only fit models with parameters $\\hat{\\boldsymbol{\\theta}}_b$ for\n",
    "    which\n",
    "-   sampling unit $i$ not used in the $b^{\\text{th}}$ resampled\n",
    "    training set.\n",
    "\n",
    "Writing $R_b$ to indicate the set of sampling units included in the\n",
    "$b^{\\text{th}}$ resampled training set:\n",
    "$$\\label{eq:loo-boot}\n",
    "\\hat{\\Omega}^{\\text{loo-boot}} = \\frac{1}{n} \\sum\\limits_{i} {\n",
    "    \\frac{1}{|\\{b \\mid i \\notin R_b \\}|}\n",
    "    \\sum\\limits_{\\{b \\mid i \\notin R_b \\}} \\hat{\\Omega}(\\hat{\\boldsymbol{\\theta}}_b, y_i)\n",
    "}$$\n",
    "(Aside re: set notation: $\\{b \\mid i \\notin R_b \\}$ is set of\n",
    "bootstrap iterations $b$ for which sampling unit $i$ does not appear\n",
    "in the set of sampling units $R_b$, while $|{b i R_b }|$\n",
    "is the number of elements in this set, that is, the number of\n",
    "bootstrap iterations which omitted sampling unit $i$.)\n",
    "\n",
    "But while $\\{\\hat{\\Omega}_b^{\\text{full}}\\}$ are generally overly\n",
    "optimistic, $\\hat{\\Omega}^{\\text{loo-boot}}$ may be too\n",
    "*pessimistic*, since each bootstrap case-resampled training set\n",
    "generally contains only a fraction $1-\\frac{1}{e} \\approx 0.632$ of\n",
    "the true training sampling units (albeit with some showing up multiple\n",
    "times!).\n",
    "\n",
    "Since repeating training sampling units doesn't generally improve\n",
    "models---the repeated units aren't really new data!---we are\n",
    "effectively learning models using only $\\approx 63.2%$ of the\n",
    "available data (albeit randomly upweighting some sampling units\n",
    "relative to others).\n",
    "[@efron1997improvements] showed that\n",
    "$$\\label{eq:632-bootstrap}\n",
    "\\hat{\\Omega}^{.632} = 0.368 \\, \\hat{\\Omega}^{\\text{resub}} + 0.632 \\, \\hat{\\Omega}^{\\text{loo-boot}}$$\n",
    "strikes a good balance between the optimism of $\\hat{\\Omega}^{\\text{resub}}$\n",
    "and the pessimism of $\\hat{\\Omega}^{\\text{loo-boot}}$ in some situations.\n",
    "\n",
    "However, in cases where overfitting is more severe,\n",
    "[@efron1997improvements] recommend\n",
    "$$\\label{eq:632plus-bootstrap}\n",
    "\\hat{\\Omega}^{.632+} =\n",
    "(1-\\hat{w}) \\, \\hat{\\Omega}^{\\text{resub}} +\n",
    "\\hat{w} \\, \\hat{\\Omega}^{\\text{loo-boot}}$$\n",
    "where $\\hat{w} \\in [1-\\frac{1}{e}, 1]$ depends on the degree of\n",
    "overfitting.\n",
    "\n",
    "There is a standard formula for calculating $\\hat{w}$ for estimating\n",
    "prediction error using the .632+ bootstrap which you can look up;\n",
    "aside from [@efron1997improvements], [@hastie2009elements] has\n",
    "a nice treatment.\n",
    "\n",
    "OK, let's get back to a concrete example: we'll use bootstrapping to\n",
    "assess the performance of a select-10-feature-for-SVM-modeling\n",
    "pipeline using 25 bootstrap resamples (this is a relatively low number\n",
    "for illustration purposes only; most sources suggest $100$\n",
    "resamples with bootstrapping, but that takes a while!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "fsSvmCaretized = list(\n",
    "    library = \"genefilter\",\n",
    "    type = \"Classification\",\n",
    "    parameters = data.frame(\n",
    "        parameter = c(\"m\", \"sigma\"),\n",
    "        class = c(\"integer\", \"numeric\"),\n",
    "        label = c(\"number features\", \"inverse kernel width\")\n",
    "    ),\n",
    "    grid = function(x, y, len=NULL, ...) {data.frame(m=10, sigma=0.025)},\n",
    "    fit = function(x, y, param, ...) {\n",
    "        featSelFit(x, y,\n",
    "                   selector = bindArgs(selectByTTest, m=param$m),\n",
    "                   fitter = bindArgs(svmFitter, sigma=param$sigma))\n",
    "    },\n",
    "    predict = function(modelFit, newdata, ...) {predict(modelFit, newdata)},\n",
    "    prob = NULL\n",
    ")\n",
    "caretOut = train(x = data.frame(t(hessTrain)),\n",
    "                 y = hessTrainY,\n",
    "                 method = fsSvmCaretized,\n",
    "                  ## here do only 25 bootstrap resamples for speed;\n",
    "                  ## (usually recommended to do >= 100 in real usage!)\n",
    "                 trControl = trainControl(\"boot632\", number=25))\n",
    "caretOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "Decision Tree Classifiers\n",
    "=========================\n",
    "\n",
    "Decision trees are probably understood by considering an example. A\n",
    "single decision tree can be constructed in R using the function\n",
    "`rpart` (for \"recursive partitioning\"). As this function is\n",
    "another formula-interface modeling function, we'll go ahead and define\n",
    "an adapter function giving it into a simpler (though less flexible) x,\n",
    "y argument structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "library(rpart)\n",
    "rpartFitter = function(x, y, control) {\n",
    "    rpart(y ~ .,\n",
    "          data = data.frame(x, check.names=FALSE),\n",
    "          method = \"class\",   ## use method = \"anova\" for regression\n",
    "          control = control)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "The standard process of fitting a decision trees actually performs a\n",
    "form of embedded feature selection, but the `rpart` function\n",
    "specifically has some unfortunate technical difficulties with very\n",
    "high-dimensional data sets, so we'll connect our by now old-hat\n",
    "$t$-test feature selector upstream of $rpartFitter$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "fsDecTree = featSelFit(\n",
    "    x = t(hessTrain),\n",
    "    y = hessTrainY,\n",
    "    selector = bindArgs(selectByTTest, m=100),\n",
    "    fitter = bindArgs(\n",
    "        rpartFitter,\n",
    "        control = rpart.control(\n",
    "            minsplit = 10,    ## don't split if < 10 sampling units in bin\n",
    "            maxdepth = 3      ## split splits of splits but no more!\n",
    "        )\n",
    "    )\n",
    ")\n",
    "plot(fsDecTree$fit, uniform=TRUE, margin=0.05)\n",
    "text(fsDecTree$fit, use.n=TRUE, all=TRUE, cex=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "Each node of the tree shown is associated with a subset of the set of\n",
    "all sampling units. The topmost (or root) node contains all samples,\n",
    "which are then split (or partitioned) into those samples for which the\n",
    "expression level for probe set 212745_s_at was measured to be \\<\n",
    "7.673, which flow down to the left node, and those samples with higher\n",
    "levels of 212745_s_at expression, which go down the right\n",
    "branch. The fitting algorithm selected the probe set 212745_s_at and\n",
    "the level 7.673 for the top split because this was determined to be\n",
    "the best single split to separate pCR patient samples from RD patient\n",
    "samples.\n",
    "\n",
    "The \"recursive\" part of recursive partitioning is then to repeat\n",
    "this splitting process within each of those sample subpopulations,\n",
    "*unless* one of the stopping criteria is met. Stopping criteria\n",
    "are usually based on the size and \"impurity\" of the sample\n",
    "subpopulation: If the node is associated with too small a sample\n",
    "subpopulation it will not be split, or if the sample subpopulation\n",
    "within the node is sufficiently pure in either one outcome class or\n",
    "the other (either close to all pCR or close to all RD), there is no\n",
    "point in further splitting.\n",
    "\n",
    "Classification probabilities for any new sample may then be calculated\n",
    "by starting at the root and following the branches of the tree\n",
    "indicated the sample's feature values until a terminal, or leaf, node\n",
    "is reached: the fraction of training set samples in the leaf node with\n",
    "classification RD is then the predicted probability that patient from\n",
    "which the new sample is derived will suffer from residual invasive\n",
    "disease (RD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "fsDecTreeTestPredProbs = predict(fsDecTree, t(hessTest))\n",
    "head(fsDecTreeTestPredProbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "fsDecTreeTestPredClass = predict(fsDecTree, t(hessTest), type=\"class\")\n",
    "table(fsDecTreeTestPredClass, hessTestY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "Single decision trees are simple and intuitive but, despite the\n",
    "reasonably good results seen just above, have generally not performed\n",
    "very well in real world classification tasks. The structure of such\n",
    "trees also tends to be very sensitive to small changes in the training\n",
    "data; don't be surprised if you get an entirely different tree if a\n",
    "single sampling unit is added or removed from the training data set!\n",
    "\n",
    "There is, however, an approach to machine learning based on multiple\n",
    "decision trees which has become very popular in the last few\n",
    "decades\\...\n",
	"\n",
    "Bagging: **Bootstrap** **Agg**regat**ing** Models \n",
    "=================================================\n",
    "\n",
    "We could consider using set of $B$ bootstrap case-resample trained\n",
    "models in place of a single model for making predictions.\n",
    "Repeat for $b {1,...,B}$:\n",
    "1.  Generate $\\mathbf{\\underline{X}}_b$ by drawing $n$\n",
    "    random integers $R_b=\\{r_{b i}\\}$ with replacement\n",
    "    and setting $x_{b ig} = x_{r_{b i} g}$, $y_{b i} = y_{r_{b i}}$.\n",
    "2.  Fit model using $\\mathbf{\\underline{X}}_b$ and $\\mathbf{y}_b$ to\n",
    "    obtain fitted parameters $\\hat{\\boldsymbol{\\theta}}_b$.\n",
    "\n",
    "Bagged predictions for new datum with feature vector $\\mathbf{x}$ by\n",
    "simply averaging together the predictions of each bagged submodel $b$\n",
    "with parameters $\\hat{\\boldsymbol{\\theta}}_b$ for features $\\mathbf{x}$.\n",
    "From [@breiman1996bagging]:\n",
    "> For unstable procedures bagging works well ...The evidence,\n",
    "> both experimental and theoretical, is that bagging can push a\n",
    "> good but unstable procedure a significant step towards optimality.\n",
    "> On the other hand, it can slightly degrade the performance of stable\n",
    "> procedures.\n",
    "\n",
    "In this context, \"stability\" is of the fit model parameters\n",
    "$\\boldsymbol{\\theta}$ with respect to the training data\n",
    "$\\{\\mathbf{x}_i, y_i\\}$. Recall that I said in section\n",
    "[sec:decision-trees](#Decision-Tree-Classifiers) that decision trees suffered\n",
    "from exactly this sort of instability!\n",
    "\n",
    "In fact the most well-known application of bagging is indeed the\n",
    "generation of *random forests* of decision trees\n",
    "([@breiman1999random]). A random forest is constructed by\n",
    "repeating, for $b {1,...,B}$:\n",
    "1.  Generate $\\mathbf{\\underline{X}}_b$ and $\\mathbf{y}_b$ by drawing $n$ random\n",
    "    integers $R_b=\\{1 \\leq r_{b i} \\leq n\\}$ with replacement and setting\n",
    "    $x_{b ig} = x_{r_{b i} g}$ and $y_{b i} = y_{r_{b i}}$.\n",
    "2.  Randomly select $m' < m$ of the features and fit a decision tree\n",
    "    classifier for $\\mathbf{y}_b$ using the columns of feature matrix\n",
    "    $\\mathbf{\\underline{X}}_b$ corresponding to those features.\n",
    "    -   $m'$ random features redrawn for each new split.\n",
    "    -   Commonly $m' \\approx \\sqrt{m}$.\n",
    "    \n",
    "The `randomForest` package in R includes a function of the same name\n",
    "which is quite easy to use (and even handles high-dimensional data\n",
    "sets smoothly, as it already has a non-formula interface built in):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "## install.packages(\"randomForest\")  ## uncomment and run if necessary\n",
    "library(randomForest)\n",
    "set.seed(321)                        ## replicability\n",
    "rf = randomForest(x = data.frame(t(hessTrain), check.names=FALSE),\n",
    "                  y = hessTrainY,\n",
    "                  nodesize = 10,     ## randomForest version of minsplit\n",
    "                  ntree = 100)\n",
    " ## default predict for randomForest is type=\"class\";\n",
    " ## (use type=\"prob\" if you want probabilities in predict call)\n",
    "rfPredClass = predict(rf, data.frame(t(hessTest), check.names=FALSE))\n",
    "table(rfPredClass, hessTestY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "So\\...here we found that a single decision tree combined with upstream\n",
    "simple $t$-test feature selection of 100 probe sets outperformed a\n",
    "random forest of 100 trees. Don't think this is a typical\n",
    "result---random forests have been found to generate very competitive\n",
    "ML classifiers in a wide variety of situations, while single decision\n",
    "trees generally have not. But it does go to show that it can be hard\n",
    "to generalize about ML algorithm performance, especially on relatively\n",
    "small data sets like the Hess example here!\n",
    "Classification Performance Metrics \n",
    "==================================\n",
    "\n",
    "There are many ways to measure performance for classifiers, of which\n",
    "accuracy is only one. Like accuracy, most are based the discrete\n",
    "classification label calls. For classifiers which output probability\n",
    "scores, this means that some threshold probability $\\psi$ (often, but\n",
    "certainly not always, 0.5) must be set.\n",
    "\n",
    "For binary (two-class) classification, when one class can be\n",
    "considered \"positive\" and the other \"negative, the cells of the 2x2\n",
    "contingency table are often labeled as true positive (TP), true\n",
    "negative (TN), false positive (FP), and false negative (FN), where,\n",
    "e.g., a false positive is sampling unit which the classifier declares\n",
    "positive but for which the true value of the outcome is negative.\n",
    "\n",
    "We could consider the values of such hard-call metrics over range of\n",
    "threshold values $\\psi$. The so-called receiver operating\n",
    "characteristic (ROC) curve ([@fawcett2006introduction]) does this\n",
    "for sensitivity and specificity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    " ## pick 20 test samples to score with pcaSvmFit classifier:\n",
    "set.seed(123)\n",
    "xfew = t(hessTest[ , sample(colnames(hessTest), 20)])\n",
    "yis1 = hessTestY[rownames(xfew)] == \"RD\"\n",
    "names(yis1) = rownames(xfew)\n",
    " ## do the scoring:\n",
    "fewPredProbs = predict(pcaSvmFit, xfew, type=\"prob\")[ , \"RD\"]\n",
    "names(fewPredProbs) = rownames(xfew)\n",
    " ## set up vector all threshold values at which a call would change:\n",
    "thresholds = c(none=1, sort(fewPredProbs, decreasing=TRUE), all=0)\n",
    " ## calculate number true positives at each threshold:\n",
    "tp = sapply(thresholds, function(thresh) {\n",
    "    sum(fewPredProbs > thresh & yis1)\n",
    "})\n",
    " ## and also number true negatives at each threshold:\n",
    "tn = sapply(thresholds, function(thresh) {\n",
    "    sum(fewPredProbs <= thresh & !yis1)\n",
    "})\n",
    " ## scale these by totals to obtain sens, spec at each threshold value:\n",
    "sensitivity = tp / sum(yis1)\n",
    "specificity = tn / sum(!yis1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "Having calculated sensitivity and specificity at every meaningful\n",
    "threshold value, we can now plot the ROC curve using `ggplot` (I\n",
    "should mention that there are several R packages that will do all of\n",
    "this work for you, but I want a very specific format for the plot\n",
    "here):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "ggdata = data.frame(\n",
    "    sample = names(sensitivity),\n",
    "    actual_class = as.numeric(yis1[names(sensitivity)]),\n",
    "    score = fewPredProbs[names(sensitivity)],\n",
    "    sensitivity = sensitivity,\n",
    "    specificity = specificity\n",
    ")\n",
    "gg = ggplot(ggdata, aes(x=1-specificity, y=sensitivity))\n",
    "gg = gg + geom_line(aes(color=score), size=1, alpha=0.75)\n",
    "gg = gg + geom_text(mapping = aes(label=sample),\n",
    "                    data = ggdata[ggdata$actual_class == 1, ],\n",
    "                    color = \"red\")\n",
    "gg = gg + geom_text(mapping = aes(label=sample),\n",
    "                    data = ggdata[ggdata$actual_class == 0, ],\n",
    "                    angle = -90,\n",
    "                    color = \"black\")\n",
    "gg = gg + geom_hline(mapping = aes(yintercept=sensitivity),\n",
    "                     data = ggdata[ggdata$actual_class == 1, ],\n",
    "                     alpha = 0.35,\n",
    "                     size = 0.25)\n",
    "gg = gg + geom_vline(mapping = aes(xintercept=1-specificity),\n",
    "                     data = ggdata[ggdata$actual_class == 0, ],\n",
    "                     alpha = 0.35,\n",
    "                     size = 0.25)\n",
    "gg = gg + scale_color_gradientn(\n",
    "    colors = c(\"orangered\", \"goldenrod\", \"seagreen\", \"dodgerblue\",\n",
    "               rgb(96/255, 96/255, 96/255))\n",
    ")\n",
    "print(gg + theme_classic())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "You can see in this plot that there are 13 RD (or\n",
    "\"positive\") and 7 pCR (\"negative\") samples in the\n",
    "subampled test data `xfew`: 5 of the\n",
    "7 negative samples---M146, M141, M485, M331, M316---have\n",
    "lower prediction scores than any of the 13 positive samples.\n",
    "Thus, there are 5 times 13 =\n",
    "65 light gray vertices below the\n",
    "ROC curve in the 5 columns on the right of\n",
    "the plot.\n",
    "\n",
    "Adding to this the 9 light gray verices below the ROC curve along the\n",
    "vertical line labeled by sample M442, corresponding to the 9 positive\n",
    "samples with scores higher than that of the negative sample M442, we\n",
    "obtain 74 total ways of pairing one of the positive samples with one\n",
    "of the negative samples for which the positive sample has a higher\n",
    "score than the negative.\n",
    "\n",
    "This corresponds to a fraction of 74 out of the 91, or 0.8132, vertices in the plot\n",
    "which lie below the curve. This shows that the area under the curve (AUC)\n",
    "for the ROC curve is 0.8132,\n",
    "which must also be the likelihood that if we randomly pick one positive sample\n",
    "and one negative sample from these 20 the positive sample will have a higher\n",
    "score than the negative.\n",
    "\n",
    "The ROC AUC score is one the most popular metrics for assessing\n",
    "classifier performance. Beyond being threshold-independent---since it\n",
    "aggregates over all possible thresholds by considering the full ROC\n",
    "curve---it has the property that an uninformative classifier will have\n",
    "an AUC of 0.5 even when the two classes are unbalanced (more of one\n",
    "than the other), as they are in the Hess data (almost 3x as many RD as\n",
    "pCR).\n",
    "\n",
    "This is not the case with accuracy: if you just assign all sampling\n",
    "units the same classification score (ignoring all feature values) and\n",
    "then set the classification threshold so that they are all called the\n",
    "more common class, the accuracy will be the > 0.5 fraction assigned to\n",
    "that class (almost 0.75 in the case of the Hess set!).\n",
    "\n",
    "We don't usually want to do all of the work we did above to assess the\n",
    "AUC score for a classifier; here are two easier ways to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    " ## calculate ROC-AUC using pROC::auc\n",
    "## install.packages(\"pROC\")  ## uncomment and run if necessary\n",
    "library(pROC)\n",
    "pROC::auc(as.numeric(yis1), fewPredProbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    " ## or can calculate from wilcox.test statistic:\n",
    " ## (this nonparametric test is based on same underlying information):\n",
    "wilcoxResults = wilcox.test(fewPredProbs[yis1], fewPredProbs[!yis1])\n",
    "wilcoxResults$statistic / (sum(yis1) * sum(!yis1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "(In other words, the ROC AUC score is essentially a more interpretable\n",
    "rescaling of the Wilcoxon-Mann-Whitney test (also known as the\n",
    "Mann-Whitney U test) statistic. This makes sense in light of the\n",
    "intepretation of AUC as the chance that a randomly chosen positive\n",
    "case has a higher classification score than does a randomly chosen\n",
    "negative case, since the Wilcoxon-Mann-Whitney test is based on this\n",
    "same idea.)\n",
    "\n",
    "Of course, we can get better estimate of the AUC using the\n",
    "*whole* test set instead of just `xfew`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "pcaSvmTestPredProbs = predict(pcaSvmFit, t(hessTest), type=\"prob\")\n",
    "pROC::auc(as.numeric(hessTestY), pcaSvmTestPredProbs[ , \"RD\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "So, a bit worse---but this still shows thus that even though\n",
    "`pcaSvmFit` only managed to correctly call 2 of the 13 test pCR\n",
    "samples as negative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "table(pcaSvmTestPredictionClass, hessTestY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "the scores of the negative (pCR) samples still tend to be lower than\n",
    "the scores of the positive (RD) samples, even if they are above the\n",
    "default threshold $\\psi=0.5$.\n",
    "Wrap-up: Comparing Models by AUC \n",
    "--------------------------------\n",
    "\n",
    "Let's go back and try a quick head-to-head comparison of five of the\n",
    "different classification models we've covered. First let's make sure\n",
    "we have all of the necessary libraries loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "library(caret)         ## knn3\n",
    "library(glmnet)\n",
    "library(kernlab)       ## ksvm\n",
    "library(HiDimDA)       ## Dlda\n",
    "library(randomForest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "We're going to use on the `apply` family of functions---`sapply`\n",
    "this time---to loop through the five different classification\n",
    "strategies. This function wants to be supplied a list to work with,\n",
    "and if the list has names, `sapply` will retain those names in\n",
    "the output data structure, so we'll assign those as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "downstreamFitters = list(\n",
    "    knn = bindArgs(knn3, k=9),\n",
    "    l2logistic = bindArgs(regularizedGLM, family=binomial, alpha=0),\n",
    "    dlda = Dlda,\n",
    "    svm = svmFitter,\n",
    "    randomForest = bindArgs(randomForest, ntree=500, nodesize=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "In order to compute ROC AUC scores, we'll need to extract prediction\n",
    "probability scores from each model; because different R packages\n",
    "handle probabilistic prediction differently, it is useful to define a\n",
    "convenience function to handle all of the relevant cases and return\n",
    "the probability scores in a unified format. We'll return these as\n",
    "simple vectors containing the predicted probability of RD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    " ## need single function to make probabilistic predictions\n",
    " ## from all of the classifiers, some require special handling:\n",
    "predictProbs = function(modelFit, newdata, ...) {\n",
    "    testPredProbs = predict(modelFit, newdata, type=\"prob\")\n",
    "    if (is.list(testPredProbs) && (\"Z\" %in% names(testPredProbs))) {\n",
    "         ## HiDimDA::Dlda doesn't directly provide probability scores,\n",
    "         ## but does provide related scores in list element Z\n",
    "        testPredProbs = testPredProbs$Z[ , \"LD1\"]\n",
    "    }\n",
    "    if (is.matrix(testPredProbs)) {\n",
    "        testPredProbs = testPredProbs[ , \"RD\"]\n",
    "    }\n",
    "    return(testPredProbs)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "Now we're ready to hook up a common upstream feature selection\n",
    "strategy (guess which one we'll use!) to each of the\n",
    "`downstreamFitters`, fit the resulting pipeline, make predictions on\n",
    "the test set, and calculate the resulting AUC scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "fsAucs = sapply(downstreamFitters, function(downstreamFitter) {\n",
    "    fitModel = featSelFit(\n",
    "        x = data.frame(t(hessTrain), check.names=FALSE),\n",
    "        y = hessTrainY,\n",
    "        selector = bindArgs(selectByTTest, m=30),\n",
    "        fitter = downstreamFitter\n",
    "    )\n",
    "    return(as.numeric(pROC::auc(\n",
    "        as.numeric(hessTestY),\n",
    "        predictProbs(fitModel, data.frame(t(hessTest), check.names=FALSE))\n",
    "    )))\n",
    "})\n",
    "fsAucs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
   "source": [
    "Interesting to note that the simplest strategy, knn, ends up winning\n",
    "according to this comparison! Lots of caveats here: the results might\n",
    "look very different with different methods of feature selection or\n",
    "extraction, different numbers of features retained, different settings\n",
    "of the various modeling parameters (number of nearest neighbors, SVM\n",
    "cost or sigma parameters, number of trees in random forests, etc.), so\n",
    "I wouldn't advise reading too much into this beyond this: sometimes\n",
    "simplicity works."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
